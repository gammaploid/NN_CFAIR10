digraph {
	graph [size="18.45,18.45"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140347984599936 [label="
 ()" fillcolor=darkolivegreen1]
	140347983814640 [label=MeanBackward0]
	140347983816080 -> 140347983814640
	140347983816080 [label=AddmmBackward0]
	140347983810992 -> 140347983816080
	140347323571952 [label="22.bias
 (6)" fillcolor=lightblue]
	140347323571952 -> 140347983810992
	140347983810992 [label=AccumulateGrad]
	140347983819584 -> 140347983816080
	140347983819584 [label=LeakyReluBackward0]
	140347983817328 -> 140347983819584
	140347983817328 [label=AddmmBackward0]
	140347983813392 -> 140347983817328
	140347323566112 [label="19.bias
 (512)" fillcolor=lightblue]
	140347323566112 -> 140347983813392
	140347983813392 [label=AccumulateGrad]
	140347983813872 -> 140347983817328
	140347983813872 [label=LeakyReluBackward1]
	140347128430896 -> 140347983813872
	140347128430896 [label=AddmmBackward0]
	140347136824736 -> 140347128430896
	140347984385024 [label="16.bias
 (512)" fillcolor=lightblue]
	140347984385024 -> 140347136824736
	140347136824736 [label=AccumulateGrad]
	140347136825312 -> 140347128430896
	140347136825312 [label=ReshapeAliasBackward0]
	140347136824832 -> 140347136825312
	140347136824832 [label=MaxPool2DWithIndicesBackward0]
	140347136824784 -> 140347136824832
	140347136824784 [label=LeakyReluBackward0]
	140347136825024 -> 140347136824784
	140347136825024 [label=ConvolutionBackward0]
	140347331407552 -> 140347136825024
	140347331407552 [label=LeakyReluBackward1]
	140347331402752 -> 140347331407552
	140347331402752 [label=ConvolutionBackward0]
	140347331407744 -> 140347331402752
	140347331407744 [label=MaxPool2DWithIndicesBackward0]
	140347331397472 -> 140347331407744
	140347331397472 [label=LeakyReluBackward1]
	140347333258800 -> 140347331397472
	140347333258800 [label=ConvolutionBackward0]
	140347333259904 -> 140347333258800
	140347333259904 [label=LeakyReluBackward1]
	140347136034176 -> 140347333259904
	140347136034176 [label=ConvolutionBackward0]
	140347136034272 -> 140347136034176
	140347136034272 [label=MaxPool2DWithIndicesBackward0]
	140347136034032 -> 140347136034272
	140347136034032 [label=LeakyReluBackward0]
	140347136033264 -> 140347136034032
	140347136033264 [label=ConvolutionBackward0]
	140347136032880 -> 140347136033264
	140347136032880 [label=LeakyReluBackward0]
	140347136033312 -> 140347136032880
	140347136033312 [label=ConvolutionBackward0]
	140347136033600 -> 140347136033312
	140347987084064 [label="0.weight
 (32, 3, 3, 3)" fillcolor=lightblue]
	140347987084064 -> 140347136033600
	140347136033600 [label=AccumulateGrad]
	140347136033408 -> 140347136033312
	140347987093744 [label="0.bias
 (32)" fillcolor=lightblue]
	140347987093744 -> 140347136033408
	140347136033408 [label=AccumulateGrad]
	140347136033360 -> 140347136033264
	140347987089184 [label="2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140347987089184 -> 140347136033360
	140347136033360 [label=AccumulateGrad]
	140347136033120 -> 140347136033264
	140347987093264 [label="2.bias
 (32)" fillcolor=lightblue]
	140347987093264 -> 140347136033120
	140347136033120 [label=AccumulateGrad]
	140347136034224 -> 140347136034176
	140347986697728 [label="5.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140347986697728 -> 140347136034224
	140347136034224 [label=AccumulateGrad]
	140347136033984 -> 140347136034176
	140347987085504 [label="5.bias
 (64)" fillcolor=lightblue]
	140347987085504 -> 140347136033984
	140347136033984 [label=AccumulateGrad]
	140347136033456 -> 140347333258800
	140347987086864 [label="7.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140347987086864 -> 140347136033456
	140347136033456 [label=AccumulateGrad]
	140347136033072 -> 140347333258800
	140347984459040 [label="7.bias
 (64)" fillcolor=lightblue]
	140347984459040 -> 140347136033072
	140347136033072 [label=AccumulateGrad]
	140347331406592 -> 140347331402752
	140347984454240 [label="10.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	140347984454240 -> 140347331406592
	140347331406592 [label=AccumulateGrad]
	140347331398816 -> 140347331402752
	140347984455680 [label="10.bias
 (128)" fillcolor=lightblue]
	140347984455680 -> 140347331398816
	140347331398816 [label=AccumulateGrad]
	140347331405776 -> 140347136825024
	140347984603056 [label="12.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140347984603056 -> 140347331405776
	140347331405776 [label=AccumulateGrad]
	140347331401168 -> 140347136825024
	140347323567792 [label="12.bias
 (128)" fillcolor=lightblue]
	140347323567792 -> 140347331401168
	140347331401168 [label=AccumulateGrad]
	140347136824880 -> 140347128430896
	140347136824880 [label=TBackward0]
	140347136824688 -> 140347136824880
	140347356887904 [label="16.weight
 (512, 2048)" fillcolor=lightblue]
	140347356887904 -> 140347136824688
	140347136824688 [label=AccumulateGrad]
	140347983813536 -> 140347983817328
	140347983813536 [label=TBackward0]
	140347983919088 -> 140347983813536
	140347323574512 [label="19.weight
 (512, 512)" fillcolor=lightblue]
	140347323574512 -> 140347983919088
	140347983919088 [label=AccumulateGrad]
	140347983812480 -> 140347983816080
	140347983812480 [label=TBackward0]
	140347983817520 -> 140347983812480
	140347323566352 [label="22.weight
 (6, 512)" fillcolor=lightblue]
	140347323566352 -> 140347983817520
	140347983817520 [label=AccumulateGrad]
	140347983814640 -> 140347984599936
}
